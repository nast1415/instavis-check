{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypF891Mfa678"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iyt5M8drbLpO"
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D\n",
    "from keras.layers import Add, Multiply\n",
    "\n",
    "from keras.layers import Input, Dense, AveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WSDgSamb8y1",
    "outputId": "3964d67e-5eff-45b9-e582-f4ab153faeb5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHrpiEDZebQG"
   },
   "source": [
    "## Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3lEEDPObz57"
   },
   "outputs": [],
   "source": [
    "img_width, img_height, channels = 160,  160, 3\n",
    "input_shape = (img_width, img_height, 3)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLrvNtMDb1Xs"
   },
   "outputs": [],
   "source": [
    "merged_imgs_dir = '<project_path>/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NldBVCvsb3BX",
    "outputId": "504393cf-1c27-49a9-83bc-f80095c88e68"
   },
   "outputs": [],
   "source": [
    "# Images preprocessing\n",
    "imgs_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  featurewise_center=True,\n",
    "                                  featurewise_std_normalization=True,\n",
    "                                  validation_split=0.08)\n",
    "\n",
    "train_generator = imgs_datagen.flow_from_directory(\n",
    "    merged_imgs_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = imgs_datagen.flow_from_directory(\n",
    "    merged_imgs_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJl985rIedWv"
   },
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP1hRcLFzB2a"
   },
   "outputs": [],
   "source": [
    "def pre_activation_residual_unit(unit_input, n_input_ch=None, \n",
    "                                 n_output_ch=None, stride=1):\n",
    "    if n_output_ch is None:\n",
    "        n_output_ch = unit_input.get_shape()[-1]\n",
    "    if n_input_ch == None:\n",
    "        n_input_ch = n_output_ch // 4\n",
    "\n",
    "    x = BatchNormalization()(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(n_input_ch, (1, 1), padding='same', strides=stride)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(n_input_ch, (3, 3), padding='same', strides=1)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(n_output_ch, (1, 1), padding='same', strides=1)(x)\n",
    "\n",
    "    if n_input_ch != n_output_ch or stride != 1:\n",
    "        unit_input = Conv2D(n_output_ch, (1, 1), \n",
    "                       padding='same', \n",
    "                       strides=(stride, stride))(unit_input)\n",
    "\n",
    "    x_added = Add()([x, unit_input])\n",
    "    return x_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X-Y-sKY2fWs"
   },
   "outputs": [],
   "source": [
    "def attention_module(input, encoder_depth=1):\n",
    "    # Hyperparameters according to the article:\n",
    "    # number of preprocessing Residual Units before splitting into trunk batch and mask batch\n",
    "    p = 1\n",
    "    # number of Residual Units in trunk batch\n",
    "    t = 2\n",
    "    # number of Residual Units between adjacent pooling layer in the mask branch\n",
    "    r = 1 \n",
    "\n",
    "    n_input_ch = input.get_shape()[-1]\n",
    "    n_output_ch = n_input_ch\n",
    "\n",
    "    # First p Residual Units\n",
    "    residual_output = input\n",
    "    for _ in range(p):\n",
    "        residual_output = pre_activation_residual_unit(residual_output)\n",
    "\n",
    "    # ---------------------------- Trunk Branch part ----------------------------\n",
    "    trunk_output = residual_output\n",
    "    for _ in range(t):\n",
    "        trunk_output = pre_activation_residual_unit(trunk_output)\n",
    "\n",
    "    # -------------------------- Soft Mask Branch part --------------------------\n",
    "    # First down sampling\n",
    "    down_sampling_output = MaxPool2D(padding='same')(residual_output)\n",
    "\n",
    "    # Apply r Resudual Units after down sampling\n",
    "    residual_output = down_sampling_output\n",
    "    for _ in range(r):\n",
    "    residual_output = pre_activation_residual_unit(residual_output)\n",
    "\n",
    "    soft_mask_output = residual_output\n",
    "\n",
    "    # Down sampling - up sampling part (with skip connections)\n",
    "    skip_connections = []\n",
    "    # Down sampling part\n",
    "    for _ in range(encoder_depth - 1):\n",
    "    # create skip connection between bottom-up and top-down parts \n",
    "    skip_connection_output = pre_activation_residual_unit(residual_output)\n",
    "    # print('Skip connection shape:', skip_connection_output.shape)\n",
    "    skip_connections.append(skip_connection_output)\n",
    "\n",
    "    # apply down sampling\n",
    "    down_sampling_output = MaxPool2D(padding='same')(residual_output)\n",
    "\n",
    "    # apply r Residual Units \n",
    "    residual_output = down_sampling_output\n",
    "    for _ in range(r):\n",
    "        residual_output = pre_activation_residual_unit(residual_output)\n",
    "\n",
    "    # reverse skip connections list (we will add connections in reverse order)\n",
    "    skip_connections = list(reversed(skip_connections))\n",
    "\n",
    "    # Up sampling part\n",
    "    for i in range(encoder_depth - 1):\n",
    "    # apply r Residual Units \n",
    "    for _ in range(r):\n",
    "        residual_output = pre_activation_residual_unit(residual_output)\n",
    "    # apply up sampling\n",
    "    up_sampling_output = UpSampling2D()(residual_output)\n",
    "\n",
    "    # adding skip connections\n",
    "    soft_mask_output = Add()([up_sampling_output, skip_connections[i]])\n",
    "\n",
    "    residual_output = soft_mask_output\n",
    "    # Final r Residual Units\n",
    "    for _ in range(r):\n",
    "        residual_output = pre_activation_residual_unit(residual_output)\n",
    "\n",
    "    # Final up sampling    \n",
    "    up_sampling_output = UpSampling2D()(residual_output)\n",
    "\n",
    "    conv_output = Conv2D(n_input_ch, (1, 1))(up_sampling_output)\n",
    "    conv_output = Conv2D(n_input_ch, (1, 1))(conv_output)\n",
    "    soft_mask_output = Activation('sigmoid')(conv_output)\n",
    "\n",
    "    # ------------- Truck and Soft Mask Branches concatenation part --------------\n",
    "\n",
    "    output = Multiply()([trunk_output, soft_mask_output])\n",
    "    output = Add()([trunk_output, output])\n",
    "\n",
    "    # Final p Residual Units\n",
    "    for _ in range(p):\n",
    "        output = pre_activation_residual_unit(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5QuF4F3ZAuI"
   },
   "outputs": [],
   "source": [
    "def att_resnet_56(shape=(160, 160, 3), n_channels=64, \n",
    "                      n_classes=9, l2_par=0.01):\n",
    "\n",
    "    reg = l2(l2_par)\n",
    "\n",
    "    model_input = Input(shape=shape)\n",
    "    x = Conv2D(n_channels, (7, 7), strides=(2, 2), padding='same')(model_input) # shape after: 80x80\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)  # shape after: 40x40\n",
    "\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 4)  # shape after: 40x40\n",
    "    x = attention_module(x, encoder_depth=2)  # shape after: 40x40\n",
    "\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 8, stride=2)  # shape after: 20x20\n",
    "    x = attention_module(x, encoder_depth=2) # shape after: 20x20\n",
    "\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 16, stride=2)  # shape after: 10x10\n",
    "    x = attention_module(x, encoder_depth=1)  # shape after: 10x10\n",
    "\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 32, stride=2)  # shape after: 5x5\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 32) # shape after: 5x5\n",
    "    x = pre_activation_residual_unit(x, n_output_ch=n_channels * 32) # shape after: 5x5\n",
    "\n",
    "    pool_size = (x.shape[1], x.shape[2])\n",
    "    x = AveragePooling2D(pool_size=pool_size, strides=(1, 1))(x) # shape after: 1x1\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    model_output = Dense(n_classes, kernel_regularizer=reg, activation='softmax')(x)\n",
    "    model = Model(model_input, model_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpko-AMQeXsf"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDStQEu8fmBD"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1AFlYifMW6Q"
   },
   "outputs": [],
   "source": [
    "att_resnet_model = att_resnet_56(n_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37h6vdUwPKNh"
   },
   "outputs": [],
   "source": [
    "att_resnet_model.compile(Adam(lr=0.0001), \n",
    "                         loss='categorical_crossentropy', \n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsahzyHlPKNW"
   },
   "outputs": [],
   "source": [
    "reducer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, \n",
    "                            min_lr=10e-7, min_delta=0.001, verbose=1)\n",
    "stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                        patience=5, verbose=1)\n",
    "\n",
    "filepath=\"<project_path>/att_resnet_best_weights.{epoch:02d}-{val_accuracy:.4f}\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "model_callbacks= [reducer, stopper, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "0HEZcNS3b4yq",
    "outputId": "0c095a0c-038b-4ffa-d7bf-d6250bfb9ded"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "att_resnet_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//batch_size, \n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples//batch_size,\n",
    "                    callbacks=model_callbacks, initial_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "att_resnet_56_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
