{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUHVpkK9bR9C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnL_WYklKy25"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "from more_itertools import sliced\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import ast\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qY0FN1pGbSU2",
    "outputId": "f7db6796-d8d7-491c-c923-7d08ea14d224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI7QAvHYHmar"
   },
   "source": [
    "## Preparing information about image merges for users\n",
    "\n",
    "We create 3 merges (with 9 photos each) for each user to download them and mark up category manually. After that we will find out all users' categories and will expand category label to the other images merges if the following conditions are met:\n",
    "* if merge from the beginning and from the middle have same labels or merge from the middle and from the end - we will mark all merges from images betweeen them with this category label\n",
    "* if all 3 merges have same labels, we will mark all merges from all user images with this category label\n",
    "* if all 3 merges have different labels or only first and last merges have the same labels, we will use only 3 existed merges in the following downloading and training (to prevent wrong labeling)\n",
    "\n",
    "**NB!** Despite tha fact that we partially automated the mark up process, after downloading all images we manually checked images classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gaHqYM49B0v"
   },
   "source": [
    "**Initial data:** We use prepared csv file `posts_for_work` with the following structure:\n",
    "* id (for user id)\n",
    "* date (date of the post publication)\n",
    "* im_url (url for downloading the image file)\n",
    "* like (number of likes for post [OPTIONAL])\n",
    "* comments (number of posts'comments [OPTIONAL])\n",
    "* followers_count (number of user's followers [OPTIONAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UhwD8vXbTqx"
   },
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('posts_for_work.csv')\n",
    "posts_df = posts_df[posts_df['is_downloaded'] == 1.]\n",
    "posts_df = posts_df[posts_df['is_outlier'] == 0.]\n",
    "posts_df = posts_df[['id', 'date', 'im_url', 'likes', 'comments', 'followers_count']]\n",
    "posts_df = posts_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYTdGG3Hew9d"
   },
   "outputs": [],
   "source": [
    "users_posts_df = posts_df.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1lrpSAhe5q7"
   },
   "outputs": [],
   "source": [
    "users = list(users_posts_df.index.values)\n",
    "counts = list(users_posts_df.date.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w07IHbgmbkeO"
   },
   "outputs": [],
   "source": [
    "# Selecting users with >= 11 photos,\n",
    "# to have at least 3 different merges (1: from 1 to 9 images, 2: 2-10, 3: 3-11)\n",
    "users_for_photos_merge = []\n",
    "for i in range(len(users)):\n",
    "    if counts[i] >= 11:\n",
    "        users_for_photos_merge.append(users[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "Kv2EFD3OfczO",
    "outputId": "0ccdd3bc-d8e2-41bd-ce36-804550b24a37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>im_url</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44700261741</td>\n",
       "      <td>1608465469</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44700261741</td>\n",
       "      <td>1608379102</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44700261741</td>\n",
       "      <td>1608278105</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44700261741</td>\n",
       "      <td>1607960552</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44700261741</td>\n",
       "      <td>1607931840</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>308</td>\n",
       "      <td>15</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151616</th>\n",
       "      <td>1091197</td>\n",
       "      <td>1596644657</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>6620</td>\n",
       "      <td>41</td>\n",
       "      <td>148084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151617</th>\n",
       "      <td>1091197</td>\n",
       "      <td>1596621865</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>10776</td>\n",
       "      <td>44</td>\n",
       "      <td>148084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151618</th>\n",
       "      <td>1091197</td>\n",
       "      <td>1596571325</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>7197</td>\n",
       "      <td>18</td>\n",
       "      <td>148084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151619</th>\n",
       "      <td>1091197</td>\n",
       "      <td>1596475464</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>10546</td>\n",
       "      <td>67</td>\n",
       "      <td>148084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151620</th>\n",
       "      <td>1091197</td>\n",
       "      <td>1596295268</td>\n",
       "      <td>https://instagram.fhel5-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>6980</td>\n",
       "      <td>33</td>\n",
       "      <td>148084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151621 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        date  ... comments  followers_count\n",
       "0       44700261741  1608465469  ...        2             5632\n",
       "1       44700261741  1608379102  ...        1             5632\n",
       "2       44700261741  1608278105  ...        4             5632\n",
       "3       44700261741  1607960552  ...        0             5632\n",
       "4       44700261741  1607931840  ...       15             5632\n",
       "...             ...         ...  ...      ...              ...\n",
       "151616      1091197  1596644657  ...       41           148084\n",
       "151617      1091197  1596621865  ...       44           148084\n",
       "151618      1091197  1596571325  ...       18           148084\n",
       "151619      1091197  1596475464  ...       67           148084\n",
       "151620      1091197  1596295268  ...       33           148084\n",
       "\n",
       "[151621 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_for_merge_df = posts_df[posts_df.id.isin(users_for_photos_merge)].reset_index(drop=True)\n",
    "posts_for_merge_df.sort_values(by=['id', 'date'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axlEMGbS2SyL"
   },
   "outputs": [],
   "source": [
    "# save selected posts\n",
    "posts_for_merge_df.to_csv('posts_for_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvlFJXKogI3B"
   },
   "outputs": [],
   "source": [
    "# main part for images grouping into merges\n",
    "user_names = []\n",
    "merge_names = []\n",
    "images_to_merge = []\n",
    "for user_id in users_for_photos_merge:\n",
    "    user_df = posts_df[posts_df['id'] == user_id].reset_index(drop=True)\n",
    "    # ids of the first images in the start, middle and final merges\n",
    "    merges_first_id = [0, int((len(user_df) - 9) // 2), len(user_df) - 9] \n",
    "\n",
    "    for start_i in range(len(merges_first_id)):\n",
    "        user_imgs_to_merge = []\n",
    "        start_id = merges_first_id[start_i]\n",
    "        for i in range(9):\n",
    "            user_imgs_to_merge.append(user_df.im_url[start_id + i])\n",
    "  \n",
    "    images_to_merge.append(user_imgs_to_merge)\n",
    "    merge_names.append(str(user_id) + '_merge' + str(start_i + 1))\n",
    "    user_names.append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yx0_yBCi-JS"
   },
   "outputs": [],
   "source": [
    "merges_dict = {'merge_name':merge_names, 'user_id':user_names, 'images':images_to_merge}\n",
    "merges_df = pd.DataFrame.from_dict(merges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVZf9BH5jDGy"
   },
   "outputs": [],
   "source": [
    "merges_df.to_csv('merges_for_labeling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgcWymNmKRGd"
   },
   "source": [
    "## Images uploading and merges creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MtZmNU2dKV9x"
   },
   "outputs": [],
   "source": [
    "merges = pd.read_csv('merges_for_labeling.csv')\n",
    "merges = merges[['merge_name', 'user_id', 'images']]\n",
    "\n",
    "# Fix arrays after uploading from csv (convert them from strings)\n",
    "merges['images'] = list(map(ast.literal_eval, merges['images'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fbtq5OAlKbvE"
   },
   "outputs": [],
   "source": [
    "# expand the merges lists of images urls into one list of all images urls when we load images in the first step\n",
    "merge_list_list = list(merges.merge_name)\n",
    "images_list = list(merges.images)\n",
    "image_download_list = []\n",
    "for i in range(len(merge_list_list)):\n",
    "    k = 0\n",
    "    for j in images_list[i]:\n",
    "        new_name = merge_list_list[i] + '__%i' %k\n",
    "        image_download_list.append([merge_list_list[i], new_name, j])\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwcw_6_SKsMZ"
   },
   "outputs": [],
   "source": [
    "df_images = pd.DataFrame(image_download_list,columns=['merge_name','image_name','im_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KPUEPtkKuNA"
   },
   "outputs": [],
   "source": [
    "from more_itertools import sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfv48WbeKuQJ"
   },
   "outputs": [],
   "source": [
    "images = list(zip(df_images.image_name, df_images.im_url))\n",
    "group_len = 115\n",
    "images_groups = list(sliced(images, group_len)) # for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8kJHG5cKuSM"
   },
   "outputs": [],
   "source": [
    "# helper function for images downloading\n",
    "def images_downloader(posts, main_path):\n",
    "    for i in range(len(posts[:])): \n",
    "        # In the case of the second stage of loading, when images are downloaded to class folders and users, \n",
    "        # the parameter 'posts' length should be 4 and contain the class_lbl and user_id lists\n",
    "        if len(posts) == 4:\n",
    "            main_path = main_path + '/' + posts[i][2] + '/' + posts[i][3] + '/'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(posts[i][1], myPath + posts[i][0])\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "# main function for parallel downloading images by prepared urls\n",
    "def parallel_downloading(images_groupes, it=0, step=10, n_processes=10)\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    while it <= len(images_groups1) - step:\n",
    "        print(it)\n",
    "        if __name__ == '__main__':\n",
    "            pool = Pool(n_processes) # set processes number    \n",
    "            result = pool.map(images_downloader, images_groups[it : it + step])\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        it = it + step\n",
    "        print('time - %f' %(timeit.default_timer() - start))\n",
    "        \n",
    "    # download last portion of data\n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(n_processes) # set processes number     \n",
    "        result = pool.map(images_downloader, images_groups[it:])\n",
    "        pool.close()\n",
    "        pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5o2BnqCKuUi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# start downloading images to the <images_data_path> directory\n",
    "parallel_downloading(images_groups, '<images_data_path>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMBnZarlKuXV"
   },
   "outputs": [],
   "source": [
    "# checking downloaded images\n",
    "downloaded_im = []\n",
    "for i in files_posts:\n",
    "    downloaded_im = downloaded_im + [i.replace('.jpg','')]\n",
    "\n",
    "# set label 1 to those images in DataFrame, which were downloaded\n",
    "df_images.loc[df_images.image_name.isin(downloaded_im), 'is_downloaded'] = 1\n",
    "df_images['is_downloaded'] = df_images['is_downloaded'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0_MgdjRKuau"
   },
   "outputs": [],
   "source": [
    "# update DataFrame\n",
    "downl_post_count = df_images.groupby('merge_name')[['is_downloaded']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ98aGhKLIEA"
   },
   "outputs": [],
   "source": [
    "# select only those initial merges, where all 9 images were downloaded\n",
    "df_images = df_images[df_images.merge_name.isin(downl_post_count[downl_post_count.is_downloaded==9].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXdQzBQBLIGW"
   },
   "outputs": [],
   "source": [
    "# group images back for merges creation\n",
    "for_merges = df_images.groupby('merge_name')['image_name'].apply(list).to_dict()\n",
    "for_merges_list = [[k,v] for k,v in zip(for_merges.keys(),for_merges.values())]\n",
    "\n",
    "# create groups for parallel merges creation  \n",
    "merges_groups = list(sliced(for_merges_list, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KS8jyzD7LII8"
   },
   "outputs": [],
   "source": [
    "# function for 9 images concatenation\n",
    "def concat_imgs(imgs_lst):\n",
    "    img_h = imgs_lst[0].height\n",
    "    img_w = imgs_lst[0].width\n",
    "    dst = Image.new('RGB', (3 * img_w, 3 * img_h))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            dst.paste(imgs_lst[i * 3 + j], (img_w * j, img_h * i))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "os0tml4aLIK3"
   },
   "outputs": [],
   "source": [
    "# main images merging function\n",
    "def merge_images(parameters):\n",
    "    for parameter_group in parameters:\n",
    "        merges_list = parameter_group[1]\n",
    "        merges_name = parameter_group[0]\n",
    "\n",
    "        merge = merges_list\n",
    "        uploaded_imgs = []\n",
    "        for img_name in merge:\n",
    "            uploaded_imgs.append(Image.open('<data_for_merges_path>/' + img_name + '.jpg'))\n",
    "        image = concat_imgs(uploaded_imgs)\n",
    "        image.save('<created_merges_path>/' + merges_name + '.jpg')\n",
    "\n",
    "def parallel_merges_creation(merges_groups, it = 1, step = 10, n_processes=10)\n",
    "  start = timeit.default_timer()\n",
    "\n",
    "    while it <= len(merges_groups) - step:\n",
    "        print(it)\n",
    "        if __name__ == '__main__':\n",
    "            pool = Pool(n_processes) # set number of processes   \n",
    "            result = pool.map(merge_images, merges_groups[it : it + step])\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        it = it + step\n",
    "        print('time - %f' %(timeit.default_timer() - start))\n",
    "    # final portion of images to merge\n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(n_processes) # set number of processes   \n",
    "        result = pool.map(merge_images, merges_groups[it:])\n",
    "        pool.close()\n",
    "        pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZzhHRJbMekf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parallel_merges_creation(merges_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7Yp99keNWzA"
   },
   "outputs": [],
   "source": [
    "# create final excel file with merges names (for labeling)\n",
    "files_posts = os.listdir('merges')\n",
    "merges_labeling = pd.DataFrame(files_posts,columns=['merge_name'])\n",
    "merges_labeling.to_excel('ready_merges_for_labeling.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "selected_merges_creation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
